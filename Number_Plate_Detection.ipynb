{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgkK2qhtQxl0",
        "outputId": "f64d80c2-b876-49b2-df69-896d0aa7af9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"WNfIwAYjy3E5atGT2DPU\")\n",
        "project = rf.workspace(\"roboflow-universe-projects\").project(\"license-plate-recognition-rxg4e\")\n",
        "version = project.version(11)\n",
        "dataset = version.download(\"yolov8\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bnwWjIdT4TF",
        "outputId": "2d28f040-345c-4e81-f6ac-fd1e7e984215"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in License-Plate-Recognition-11 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 527254/527254 [00:16<00:00, 31813.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to License-Plate-Recognition-11 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20262/20262 [00:03<00:00, 6367.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmiEBd_LUFD9",
        "outputId": "9a571ac0-b93b-4646-83b2-de28b4a67ebe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import shutil, os"
      ],
      "metadata": {
        "id": "ute_ONEqUpR_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "# Load pretrained YOLOv8 nano model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train\n",
        "results = model.train(\n",
        "    data = dataset.location + \"/data.yaml\",   # use dataset path from Roboflow\n",
        "    epochs = 10,\n",
        "    imgsz = 640,\n",
        "    batch = 16,\n",
        "    workers = 2,\n",
        "    device = 0\n",
        ")\n",
        "\n",
        "# Copy weights to a safe folder\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "shutil.copy(\n",
        "    \"runs/detect/train2/weights/best.pt\",\n",
        "    \"saved_models/license_plate_best.pt\"\n",
        ")\n",
        "shutil.copy(\n",
        "    \"runs/detect/train2/weights/last.pt\",\n",
        "    \"saved_models/license_plate_last.pt\"\n",
        ")\n",
        "\n",
        "print(\"Weights saved in saved_models/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q1hKQYMU2pD",
        "outputId": "6caa3c5d-a36c-468b-af31-6a40d7bae47c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.228 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/License-Plate-Recognition-11/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 954.3Â±139.6 MB/s, size: 24.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/License-Plate-Recognition-11/train/labels.cache... 7057 images, 5 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7057/7057 11.3Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.1 ms, read: 352.0Â±158.0 MB/s, size: 20.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/License-Plate-Recognition-11/valid/labels.cache... 2048 images, 3 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2048/2048 1.3Mit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      3.78G       1.27       1.76      1.197          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.6it/s 2:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.2it/s 15.2s\n",
            "                   all       2048       2195      0.948      0.839      0.898      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      4.65G      1.265     0.8612      1.201          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.3it/s 15.0s\n",
            "                   all       2048       2195      0.936      0.856       0.91      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      4.65G       1.25     0.7379      1.183          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.7it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.5it/s 14.3s\n",
            "                   all       2048       2195      0.958      0.867      0.928      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      4.65G      1.213     0.6852      1.162          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.4it/s 14.4s\n",
            "                   all       2048       2195      0.953      0.878      0.925      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      4.65G      1.195     0.6344      1.148          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.3it/s 14.9s\n",
            "                   all       2048       2195      0.962      0.903      0.948      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      4.65G      1.157     0.5893      1.125          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.4it/s 14.6s\n",
            "                   all       2048       2195      0.961      0.905      0.948      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      4.65G      1.136     0.5554      1.113          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.4it/s 14.5s\n",
            "                   all       2048       2195      0.981      0.906      0.955      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      4.65G      1.114     0.5284      1.096          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.7it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.5it/s 14.3s\n",
            "                   all       2048       2195      0.975      0.919      0.957      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      4.65G      1.094     0.4933      1.084          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:58\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.4it/s 14.5s\n",
            "                   all       2048       2195      0.974      0.932      0.963      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      4.65G      1.071      0.471      1.071          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 442/442 3.8it/s 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 4.5it/s 14.3s\n",
            "                   all       2048       2195      0.981      0.923      0.964       0.68\n",
            "\n",
            "10 epochs completed in 0.371 hours.\n",
            "Optimizer stripped from /content/runs/detect/train3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.3.228 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 64/64 3.9it/s 16.2s\n",
            "                   all       2048       2195      0.981      0.923      0.964       0.68\n",
            "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train3\u001b[0m\n",
            "Weights saved in saved_models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQrf9fhshLWm",
        "outputId": "5f6704f0-27f1-447b-eebc-e604e3608e90"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.23.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.6.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.2)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.4.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "import re\n",
        "from collections import defaultdict, deque\n"
      ],
      "metadata": {
        "id": "7YM9AUtEi2C4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import finetuned yolo and ocr\n",
        "model = YOLO(\"saved_models/license_plate_best.pt\")  # fine-tuned weights\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Regex: 2 letters + 2 numbers + 3 letters\n",
        "plate_pattern = re.compile(r\"^[A-Z]{2}[0-9]{2}[A-Z]{3}$\")"
      ],
      "metadata": {
        "id": "_jTvFHBWjAUr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correct plate format\n",
        "def correct_plate_format(ocr_text):\n",
        "    mapping_num_to_alpha = {\"0\": \"O\", \"1\": \"I\", \"5\": \"S\", \"8\": \"B\"}\n",
        "    mapping_alpha_to_num = {\"O\": \"0\", \"I\": \"1\", \"Z\": \"2\", \"S\": \"5\", \"B\": \"8\"}\n",
        "\n",
        "    ocr_text = ocr_text.upper().replace(\" \", \"\")\n",
        "    if len(ocr_text) != 7:\n",
        "        return \"\"   # discard if wrong length\n",
        "\n",
        "    corrected = []\n",
        "    for i, ch in enumerate(ocr_text):\n",
        "        if i < 2 or i >= 4:   # alphabet positions\n",
        "            if ch.isdigit() and ch in mapping_num_to_alpha:\n",
        "                corrected.append(mapping_num_to_alpha[ch])\n",
        "            elif ch.isalpha():\n",
        "                corrected.append(ch)\n",
        "            else:\n",
        "                return \"\"   # invalid char\n",
        "        else:  # numeric positions\n",
        "            if ch.isalpha() and ch in mapping_alpha_to_num:\n",
        "                corrected.append(mapping_alpha_to_num[ch])\n",
        "            elif ch.isdigit():\n",
        "                corrected.append(ch)\n",
        "            else:\n",
        "                return \"\"   # invalid char\n",
        "\n",
        "    return \"\".join(corrected)\n"
      ],
      "metadata": {
        "id": "dLlGwP99jqtR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def recognize_plate(plate_crop):\n",
        "    if plate_crop.size == 0:\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Preprocessing (This part is already correct)\n",
        "    gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)\n",
        "    gray_blurred = cv2.medianBlur(gray, 3)\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        gray_blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 11, 2\n",
        "    )\n",
        "    plate_resized = cv2.resize(thresh, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # 2. OCR (paragraph=False)\n",
        "    try:\n",
        "        ocr_result = reader.readtext(\n",
        "            plate_resized,\n",
        "            detail=0,\n",
        "            allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
        "            paragraph=False  # This is very important\n",
        "        )\n",
        "\n",
        "        if len(ocr_result) < 1:   # If OCR didnâ€™t read anything\n",
        "            return \"\"\n",
        "\n",
        "        # --- 3. NEW: â€œJunkâ€ Filter (Trimming side garbage) ---\n",
        "\n",
        "        # Clean every OCR block\n",
        "        cleaned_blocks = []\n",
        "        for block in ocr_result:\n",
        "            clean_block = re.sub(r'[^A-Z0-9]', '', block.upper().replace(' ', ''))\n",
        "            if clean_block:  # Keep only non-empty cleaned blocks\n",
        "                cleaned_blocks.append(clean_block)\n",
        "\n",
        "        if len(cleaned_blocks) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # Check 1: Is the first block junk?\n",
        "        # (Junk = all letters AND length <= 2, like \"E\", \"SK\")\n",
        "        if cleaned_blocks[0].isalpha() and len(cleaned_blocks[0]) <= 2:\n",
        "            cleaned_blocks = cleaned_blocks[1:]   # Remove first block\n",
        "\n",
        "        if len(cleaned_blocks) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # Check 2: Is the last block junk?\n",
        "        # (Junk = all letters OR all numbers AND length <= 2, like \"CK\", \"3\", \"4\")\n",
        "        if (cleaned_blocks[-1].isalpha() or cleaned_blocks[-1].isdigit()) and len(cleaned_blocks[-1]) <= 2:\n",
        "            cleaned_blocks = cleaned_blocks[:-1]  # Remove last block\n",
        "\n",
        "        if len(cleaned_blocks) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # --- 4. Join the real text ---\n",
        "        # Now we have a junk-free list, e.g. [\"6855\", \"1079\"] or [\"XZ8X\", \"8\", \"473\"]\n",
        "        cleaned_text = \"\".join(cleaned_blocks)   # â†’ \"68551079\" or \"XZ8X8473\"\n",
        "\n",
        "        # --- 5. Formatting and Correction ---\n",
        "\n",
        "        # Case 1: \"XZ8X8473\" (length 8)\n",
        "        if len(cleaned_text) == 8 and cleaned_text.startswith('X'):\n",
        "            corrected = list(cleaned_text)\n",
        "            if corrected[1] == '2': corrected[1] = 'Z'   # Convert \"2\" â†’ \"Z\"\n",
        "            if corrected[2] == 'B': corrected[2] = '8'   # Convert \"B\" â†’ \"8\"\n",
        "            cleaned_text = \"\".join(corrected)\n",
        "            return f\"{cleaned_text[:4]} {cleaned_text[4:]}\"   # \"XZ8X 8473\"\n",
        "\n",
        "        # Case 2: \"68551079\" (length 8, all digits)\n",
        "        if len(cleaned_text) == 8 and cleaned_text.isdigit():\n",
        "            return f\"{cleaned_text[:4]} {cleaned_text[4:]}\"   # \"6855 1079\"\n",
        "\n",
        "        # Case 3: 7-digit plates (example: \"XZ8X473\" if '8' is missed)\n",
        "        if len(cleaned_text) == 7 and cleaned_text.startswith('X'):\n",
        "            return f\"{cleaned_text[:4]} {cleaned_text[4:]}\"   # \"XZ8X 473\"\n",
        "\n",
        "        # If none of the above, but text exists, return as is\n",
        "        if len(cleaned_text) >= 7:\n",
        "            return cleaned_text\n",
        "\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    return \"\"   # Return empty string if filtering fails\n"
      ],
      "metadata": {
        "id": "5tSDv2Tqj_aK"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number plate stabilization\n",
        "plate_history = defaultdict(lambda: deque(maxlen=10))  # last 10 predictions per box\n",
        "plate_final = {}\n",
        "\n",
        "# --- YEH RAHA NAYA \"SMART\" ID FUNCTION ---\n",
        "def get_box_id(x1, y1, x2, y2):\n",
        "    # Plate ka center point calculate karein\n",
        "    center_x = (x1 + x2) / 2\n",
        "    center_y = (y1 + y2) / 2\n",
        "\n",
        "    # Center point ko 50 pixel ke \"grid\" mein round karein\n",
        "    # Isse ID \"sticky\" ban jaata hai aur plate hilne par bhi change nahi hota\n",
        "    return f\"{int(center_x / 50)}_{int(center_y / 50)}\"\n",
        "\n",
        "def get_stable_plate(box_id, new_text):\n",
        "    if new_text:\n",
        "        plate_history[box_id].append(new_text)\n",
        "        # Majority vote\n",
        "        most_common = max(set(plate_history[box_id]), key=plate_history[box_id].count)\n",
        "        plate_final[box_id] = most_common\n",
        "    return plate_final.get(box_id, \"\")"
      ],
      "metadata": {
        "id": "zPbBQMYykMaM"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video = \"vehicle_video.mp4\"\n",
        "output_video = \"output_video_licenseplate.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\n",
        "    output_video, fourcc,\n",
        "    cap.get(cv2.CAP_PROP_FPS),\n",
        "    (int(cap.get(3)), int(cap.get(4)))\n",
        ")\n",
        "\n",
        "CONF_THRESH = 0.3\n"
      ],
      "metadata": {
        "id": "qqSQi-4okX6p"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- THIS IS THE CORRECT LOOP FOR GOOGLE COLAB ---\n",
        "\n",
        "# Import tqdm for progress bar (if not already imported)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup frame count and progress bar\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
        "pbar = tqdm(total=frame_count, desc=\"Processing Video\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame, verbose=False)\n",
        "\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "            conf = float(box.conf.cpu().numpy())\n",
        "            if conf < CONF_THRESH:\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
        "\n",
        "            # Keep coordinates within frame boundary (Clipping)\n",
        "            x1, y1 = max(0, x1), max(0, y1)\n",
        "            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
        "            if x2 <= x1 or y2 <= y1:  # If box is invalid, skip it\n",
        "                continue\n",
        "\n",
        "            plate_crop = frame[y1:y2, x1:x2]\n",
        "\n",
        "            # OCR with correction\n",
        "            text = recognize_plate(plate_crop)\n",
        "\n",
        "            # Stabilize text using history\n",
        "            box_id = get_box_id(x1, y1, x2, y2)\n",
        "            stable_text = get_stable_plate(box_id, text)\n",
        "\n",
        "            # Draw a rectangle around the license plate\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "            # Overlay zoomed-in plate above detected region\n",
        "            if plate_crop.size > 0:\n",
        "                overlay_h, overlay_w = 150, 400\n",
        "                plate_resized = cv2.resize(plate_crop, (overlay_w, overlay_h))\n",
        "\n",
        "                oy1 = max(0, y1 - overlay_h - 40)\n",
        "                ox1 = x1\n",
        "                oy2, ox2 = oy1 + overlay_h, ox1 + overlay_w\n",
        "\n",
        "                if oy2 <= frame.shape[0] and ox2 <= frame.shape[1]:\n",
        "                    frame[oy1:oy2, ox1:ox2] = plate_resized\n",
        "\n",
        "                # Display stabilized OCR text above overlay\n",
        "                if stable_text:\n",
        "                    cv2.putText(frame, stable_text, (ox1, oy1 - 20),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 6)  # black outline\n",
        "                    cv2.putText(frame, stable_text, (ox1, oy1 - 20),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)  # white text\n",
        "\n",
        "    # -------- WRITES THE PROCESSED FRAME TO OUTPUT VIDEO --------\n",
        "    out.write(frame)\n",
        "    pbar.update(1)  # Update progress bar\n",
        "\n",
        "    # -------- THESE LINES ARE REMOVED FOR COLAB --------\n",
        "    # cv2.imshow(\"Annotated Video\", frame)\n",
        "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    #     break\n",
        "\n",
        "# Close progress bar after loop ends\n",
        "pbar.close()\n",
        "\n",
        "# Release files/resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Video processing complete! Saved to {output_video}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD1_D7_vqA9u",
        "outputId": "f615c233-2fe9-4116-e972-8e2f8773d5de"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing Video:   0%|          | 0/192 [00:00<?, ?it/s]\u001b[AConversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "\n",
            "Processing Video:   1%|          | 2/192 [00:00<00:14, 12.96it/s]\u001b[A\n",
            "Processing Video:   2%|â–         | 4/192 [00:00<00:14, 13.26it/s]\u001b[A\n",
            "Processing Video:   3%|â–Ž         | 6/192 [00:00<00:13, 13.85it/s]\u001b[A\n",
            "Processing Video:   4%|â–         | 8/192 [00:00<00:11, 15.53it/s]\u001b[A\n",
            "Processing Video:   5%|â–Œ         | 10/192 [00:00<00:11, 15.23it/s]\u001b[A\n",
            "Processing Video:   6%|â–‹         | 12/192 [00:00<00:11, 15.64it/s]\u001b[A\n",
            "Processing Video:   7%|â–‹         | 14/192 [00:00<00:11, 15.48it/s]\u001b[A\n",
            "Processing Video:   8%|â–Š         | 16/192 [00:01<00:11, 15.93it/s]\u001b[A\n",
            "Processing Video:   9%|â–‰         | 18/192 [00:01<00:10, 15.94it/s]\u001b[A\n",
            "Processing Video:  10%|â–ˆ         | 20/192 [00:01<00:10, 15.84it/s]\u001b[A\n",
            "Processing Video:  11%|â–ˆâ–        | 22/192 [00:01<00:10, 16.62it/s]\u001b[A\n",
            "Processing Video:  12%|â–ˆâ–Ž        | 24/192 [00:01<00:09, 17.00it/s]\u001b[A\n",
            "Processing Video:  14%|â–ˆâ–Ž        | 26/192 [00:01<00:10, 16.31it/s]\u001b[A\n",
            "Processing Video:  15%|â–ˆâ–        | 28/192 [00:01<00:11, 14.67it/s]\u001b[A\n",
            "Processing Video:  16%|â–ˆâ–Œ        | 30/192 [00:01<00:11, 14.27it/s]\u001b[A\n",
            "Processing Video:  17%|â–ˆâ–‹        | 32/192 [00:02<00:11, 13.96it/s]\u001b[A\n",
            "Processing Video:  18%|â–ˆâ–Š        | 34/192 [00:02<00:11, 13.44it/s]\u001b[A\n",
            "Processing Video:  19%|â–ˆâ–‰        | 36/192 [00:02<00:11, 13.26it/s]\u001b[A\n",
            "Processing Video:  20%|â–ˆâ–‰        | 38/192 [00:02<00:11, 13.59it/s]\u001b[A\n",
            "Processing Video:  21%|â–ˆâ–ˆ        | 40/192 [00:02<00:11, 13.05it/s]\u001b[A\n",
            "Processing Video:  22%|â–ˆâ–ˆâ–       | 42/192 [00:02<00:11, 13.33it/s]\u001b[A\n",
            "Processing Video:  23%|â–ˆâ–ˆâ–Ž       | 44/192 [00:03<00:14, 10.49it/s]\u001b[A\n",
            "Processing Video:  24%|â–ˆâ–ˆâ–       | 46/192 [00:03<00:14,  9.91it/s]\u001b[A\n",
            "Processing Video:  25%|â–ˆâ–ˆâ–Œ       | 48/192 [00:03<00:16,  8.63it/s]\u001b[A\n",
            "Processing Video:  26%|â–ˆâ–ˆâ–Œ       | 49/192 [00:03<00:18,  7.81it/s]\u001b[A\n",
            "Processing Video:  26%|â–ˆâ–ˆâ–Œ       | 50/192 [00:04<00:18,  7.86it/s]\u001b[A\n",
            "Processing Video:  27%|â–ˆâ–ˆâ–‹       | 51/192 [00:04<00:18,  7.70it/s]\u001b[A\n",
            "Processing Video:  27%|â–ˆâ–ˆâ–‹       | 52/192 [00:04<00:17,  8.09it/s]\u001b[A\n",
            "Processing Video:  28%|â–ˆâ–ˆâ–Š       | 54/192 [00:04<00:14,  9.72it/s]\u001b[A\n",
            "Processing Video:  29%|â–ˆâ–ˆâ–‰       | 56/192 [00:04<00:12, 11.12it/s]\u001b[A\n",
            "Processing Video:  30%|â–ˆâ–ˆâ–ˆ       | 58/192 [00:04<00:11, 11.72it/s]\u001b[A\n",
            "Processing Video:  31%|â–ˆâ–ˆâ–ˆâ–      | 60/192 [00:04<00:10, 12.30it/s]\u001b[A\n",
            "Processing Video:  32%|â–ˆâ–ˆâ–ˆâ–      | 62/192 [00:04<00:10, 12.87it/s]\u001b[A\n",
            "Processing Video:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 64/192 [00:05<00:09, 13.49it/s]\u001b[A\n",
            "Processing Video:  34%|â–ˆâ–ˆâ–ˆâ–      | 66/192 [00:05<00:08, 14.11it/s]\u001b[A\n",
            "Processing Video:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 68/192 [00:05<00:08, 14.45it/s]\u001b[A\n",
            "Processing Video:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 70/192 [00:05<00:08, 14.81it/s]\u001b[A\n",
            "Processing Video:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 72/192 [00:05<00:08, 14.97it/s]\u001b[A\n",
            "Processing Video:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 74/192 [00:05<00:07, 15.36it/s]\u001b[A\n",
            "Processing Video:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 76/192 [00:05<00:07, 15.12it/s]\u001b[A\n",
            "Processing Video:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 78/192 [00:06<00:07, 15.24it/s]\u001b[A\n",
            "Processing Video:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/192 [00:06<00:07, 15.57it/s]\u001b[A\n",
            "Processing Video:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 82/192 [00:06<00:07, 15.71it/s]\u001b[A\n",
            "Processing Video:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/192 [00:06<00:06, 15.78it/s]\u001b[A\n",
            "Processing Video:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/192 [00:06<00:06, 15.98it/s]\u001b[A\n",
            "Processing Video:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 88/192 [00:06<00:06, 16.04it/s]\u001b[A\n",
            "Processing Video:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 90/192 [00:06<00:06, 16.08it/s]\u001b[A\n",
            "Processing Video:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 92/192 [00:06<00:06, 15.58it/s]\u001b[A\n",
            "Processing Video:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 94/192 [00:07<00:06, 15.18it/s]\u001b[A\n",
            "Processing Video:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96/192 [00:07<00:06, 15.25it/s]\u001b[A\n",
            "Processing Video:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 98/192 [00:07<00:06, 15.17it/s]\u001b[A\n",
            "Processing Video:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 100/192 [00:07<00:06, 13.41it/s]\u001b[A\n",
            "Processing Video:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 102/192 [00:07<00:06, 13.15it/s]\u001b[A\n",
            "Processing Video:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/192 [00:07<00:06, 13.18it/s]\u001b[A\n",
            "Processing Video:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 106/192 [00:07<00:06, 13.37it/s]\u001b[A\n",
            "Processing Video:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 108/192 [00:08<00:06, 12.29it/s]\u001b[A\n",
            "Processing Video:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 110/192 [00:08<00:06, 11.72it/s]\u001b[A\n",
            "Processing Video:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 112/192 [00:08<00:07, 11.32it/s]\u001b[A\n",
            "Processing Video:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 114/192 [00:08<00:06, 11.43it/s]\u001b[A\n",
            "Processing Video:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 116/192 [00:08<00:06, 11.18it/s]\u001b[A\n",
            "Processing Video:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 118/192 [00:09<00:06, 10.85it/s]\u001b[A\n",
            "Processing Video:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 120/192 [00:09<00:06, 11.26it/s]\u001b[A\n",
            "Processing Video:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 122/192 [00:09<00:05, 12.04it/s]\u001b[A\n",
            "Processing Video:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/192 [00:09<00:05, 13.03it/s]\u001b[A\n",
            "Processing Video:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 126/192 [00:09<00:05, 12.61it/s]\u001b[A\n",
            "Processing Video:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 128/192 [00:09<00:04, 13.79it/s]\u001b[A\n",
            "Processing Video:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 130/192 [00:09<00:04, 14.27it/s]\u001b[A\n",
            "Processing Video:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 132/192 [00:10<00:03, 15.13it/s]\u001b[A\n",
            "Processing Video:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 134/192 [00:10<00:04, 14.43it/s]\u001b[A\n",
            "Processing Video:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 136/192 [00:10<00:03, 14.77it/s]\u001b[A\n",
            "Processing Video:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 138/192 [00:10<00:03, 15.60it/s]\u001b[A\n",
            "Processing Video:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 140/192 [00:10<00:03, 16.39it/s]\u001b[A\n",
            "Processing Video:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/192 [00:10<00:03, 15.56it/s]\u001b[A\n",
            "Processing Video:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 144/192 [00:10<00:03, 14.84it/s]\u001b[A\n",
            "Processing Video:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 146/192 [00:10<00:03, 14.06it/s]\u001b[A\n",
            "Processing Video:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 148/192 [00:11<00:03, 12.82it/s]\u001b[A\n",
            "Processing Video:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 150/192 [00:11<00:03, 12.88it/s]\u001b[A\n",
            "Processing Video:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 152/192 [00:11<00:03, 12.75it/s]\u001b[A\n",
            "Processing Video:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 154/192 [00:11<00:03, 12.35it/s]\u001b[A\n",
            "Processing Video:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 156/192 [00:11<00:02, 12.64it/s]\u001b[A\n",
            "Processing Video:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 158/192 [00:11<00:02, 12.31it/s]\u001b[A\n",
            "Processing Video:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 160/192 [00:12<00:02, 13.62it/s]\u001b[A\n",
            "Processing Video:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 162/192 [00:12<00:02, 14.50it/s]\u001b[A\n",
            "Processing Video:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 164/192 [00:12<00:01, 14.65it/s]\u001b[A\n",
            "Processing Video:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 166/192 [00:12<00:01, 15.49it/s]\u001b[A\n",
            "Processing Video:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 169/192 [00:12<00:01, 17.27it/s]\u001b[A\n",
            "Processing Video:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 172/192 [00:12<00:01, 18.72it/s]\u001b[A\n",
            "Processing Video:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 175/192 [00:12<00:00, 19.54it/s]\u001b[A\n",
            "Processing Video:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 178/192 [00:12<00:00, 20.37it/s]\u001b[A\n",
            "Processing Video:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181/192 [00:13<00:00, 21.06it/s]\u001b[A\n",
            "Processing Video:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 184/192 [00:13<00:00, 19.91it/s]\u001b[A\n",
            "Processing Video:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 187/192 [00:13<00:00, 19.96it/s]\u001b[A\n",
            "Processing Video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192/192 [00:13<00:00, 14.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video processing complete! Saved to output_video_licenseplate.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}